Plan for Listing MCP Servers from New Websites
================================================

This plan describes how to add MCP server listings from a new website to the
research/mcplist directory. It follows the same approach used for
registry.modelcontextprotocol.io and mcpservers.org.

Prerequisites
-------------

The mcplist directory already contains:

  - gmcpt: A Go binary built from github.com/leftmike/gmcpt. If it is missing,
    build it:

      git clone https://github.com/leftmike/gmcpt.git /tmp/gmcpt
      cd /tmp/gmcpt
      # Adjust the go directive in go.mod if your Go version is older than required
      go build -o /home/user/research/mcplist/gmcpt .

  - mcp_servers.txt: Results from registry.modelcontextprotocol.io (872 servers).
  - mcpservers_org.txt: Results from mcpservers.org (24 endpoints).
  - test_servers.sh, test_mcpservers_org.sh: Test scripts (use as templates).
  - compile_results.py, fetch_registry.py: Python helpers (use as templates).

gmcpt usage:

    gmcpt list [flags] <url>

    Flags:
      -sse          Use SSE transport (required for /sse endpoints)
      -tools        Include tools in output
      -prompts      Include prompts in output
      -resources    Include resources in output
      -json         Output as JSON (parse with jq or Python json module)
      -apikey KEY   Provide an API key
      -header NAME  Header name for the API key

    Without -sse, gmcpt uses streamable-http transport.
    Timeout the command externally: timeout 15 gmcpt list ...

Step 1: Scrape the Server List
------------------------------

Fetch the target website and extract every remote MCP server entry. You need
for each server:

  (a) A human-readable name.
  (b) The connection URL (e.g. https://mcp.example.com/mcp or .../sse).
  (c) The transport type: "sse" if the URL ends in /sse or /mcpSse, otherwise
      "streamable-http". Some servers list both; treat each URL as a separate
      endpoint.

If the website has a JSON API (like registry.modelcontextprotocol.io does at
https://registry.modelcontextprotocol.io/v0.1/servers), prefer that over HTML
scraping. See fetch_registry.py for a paginated API example. If the site is
HTML only, use WebFetch to extract the data.

Save the scraped data however you like (JSON file, hardcoded array in the test
script, etc). The key requirement is that you have a list of (name, url,
transport) tuples.

Step 2: Write and Run the Test Script
--------------------------------------

Create a bash script named test_<source>.sh (e.g. test_glama_ai.sh). Use
test_mcpservers_org.sh as a template. The script must:

  1. Define the server list. Either:
     - Hardcode it in a bash array (for small lists, <50 servers), or
     - Read from a JSON file using python3 (for large lists, see test_servers.sh).

  2. For each server, run:

       timeout 15 gmcpt list $SSE_FLAG -tools -prompts -resources -json "$URL"

     where SSE_FLAG is "-sse" if transport is sse, empty otherwise.

  3. Classify the result by examining the output and exit code:

       "Forbidden"                     -> status=connection_blocked
       "Unauthorized" or "401"         -> status=auth_required, auth=yes
       "connection refused|no such host|dial tcp" -> status=connection_failed
       "timeout|deadline exceeded"     -> status=timeout
       exit_code == 124 (from timeout) -> status=timeout
       exit_code == 0                  -> status=success, auth=no
       anything else                   -> status=error

  4. Write each result to results_<source>/server_<idx>.txt in this format:

       NAME: <server name>
       URL: <endpoint url>
       TRANSPORT: <sse or streamable-http>
       AUTH_REQUIRED: <yes (confirmed by gmcpt) | no | unknown>
       STATUS: <success|auth_required|connection_blocked|connection_failed|timeout|error>
       EXIT_CODE: <number>
       OUTPUT:
       <raw gmcpt output>
       ---

  5. After all tests, compile results into a summary file. Use the embedded
     Python block at the end of test_mcpservers_org.sh as a template. The
     summary file should be named <source>.txt (e.g. glama_ai.txt) and follow
     this format:

       MCP Servers (<source>) - Authentication & Capabilities Report
       Generated by gmcpt list against <website url>
       ==============================================================================

       SUMMARY
         Total remote MCP server endpoints: N
         SSE transport: N
         Streamable HTTP transport: N

         gmcpt list results:
           Successful: N
           Auth required (confirmed by server): N
           Connection blocked (egress proxy): N
           Connection failed: N
           Timeout: N
           Other error: N

       ==============================================================================

       Server: <name>
         URL: <url>
         SSE: yes|no
         Transport: sse|streamable-http
         Auth Required: yes (...)|no|unknown
         gmcpt Status: <status>
         Tools: <comma-separated list>       (only if successful)
         Prompts: <comma-separated list>     (only if successful)
         Resources: <comma-separated list>   (only if successful)
         Error: <first 300 chars of output>  (only if error/auth/timeout)

     For successful servers, parse the JSON output to extract tool, prompt,
     and resource names:

       data = json.loads(raw_output)
       tools = [t["name"] for t in data.get("tools", [])]
       prompts = [p["name"] for p in data.get("prompts", [])]
       resources = [r.get("name", r.get("uri", "")) for r in data.get("resources", [])]

Step 3: Performance Considerations
-----------------------------------

  - For small lists (<50 servers): sequential execution is fine (as in
    test_mcpservers_org.sh).
  - For large lists (>50 servers): run tests in parallel with a concurrency
    limit of 20 (as in test_servers.sh). Use background jobs + wait -n.
  - Always use a timeout (15 seconds is good). Some servers hang indefinitely.

Step 4: Commit the Results
--------------------------

Commit these files:
  - test_<source>.sh (the test script)
  - <source>.txt (the compiled summary)
  - results_<source>/ (the raw per-server results)

Known Issues and Workarounds
-----------------------------

  - Many SSE servers that require OAuth return a "missing endpoint" error from
    gmcpt rather than a clear 401. The error looks like:
      missing endpoint: first event is "", want "endpoint"
    This usually means auth is required but cannot be confirmed programmatically.
    Classify these as status=error with auth_required=unknown.

  - Some servers are blocked by the egress proxy in this environment (status
    "Forbidden"). These show as connection_blocked.

  - URLs containing template variables like {VARIABLE} will fail. Skip these
    or classify as error.

  - The gmcpt -json flag outputs a JSON object with "tools", "prompts", and
    "resources" arrays on success. On failure it prints an error message to
    stderr. Capture both stdout and stderr (2>&1) so the error is available
    for classification.

  - If gmcpt is missing or fails to build, ensure Go is installed (go version)
    and adjust the go.mod version if needed (the repo may require a newer Go
    than what is available).

Candidate Websites
------------------

Websites known to list remote MCP servers that have NOT yet been processed:

  - https://glama.ai/mcp/servers
  - https://smithery.ai
  - https://mcp.so
  - https://mcpmarket.com
  - https://opentools.com
  - https://composio.dev/mcp
  - https://guMCP.com
  - https://pipedream.com/mcp
